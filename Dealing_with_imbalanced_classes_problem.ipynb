{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Dealing with imbalanced classes problem.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pb111/Data-Science-Portfolio-in-Python/blob/master/Dealing_with_imbalanced_classes_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGI-LjGiyhHm"
      },
      "source": [
        "# **Dealing with imbalanced classes problem**\n",
        "\n",
        "Imbalanced classes is one of the major problems in machine learning. In this data preprocessing project, I discuss the imbalanced classes problem. I present Python implementation to deal with this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eACrMhZyhHu"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "\n",
        "I have divided this project into various sections which are listed below:-\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.\tIntroduction to imbalanced classes problem\n",
        "\n",
        "2.\tProblems with imbalanced learning\n",
        "\n",
        "3.\tExample of imbalanced classes\n",
        "\n",
        "4.\tApproaches to handle imbalanced classes\n",
        "\n",
        "5.\tPython implementation to illustrate class imbalance problem\n",
        "\n",
        "6.\tPrecision - Recall Curve\n",
        "\n",
        "7.  Random over-sampling the minority class\n",
        "\n",
        "8.\tRandom under-sampling the majority class\n",
        "\n",
        "9.\tApply tree-based algorithms\n",
        "\n",
        "10.\tRandom under-sampling and over-sampling with imbalanced-learn\n",
        "\n",
        "11.\tUnder-sampling : Tomek links\n",
        "\n",
        "12.\tUnder-sampling : Cluster Centroids\n",
        "\n",
        "13.\tOver-sampling : SMOTE\n",
        "\n",
        "14.\tConclusion   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqr6UOhPyhHv"
      },
      "source": [
        "## 1. Introduction to imbalanced classes problem\n",
        "\n",
        "\n",
        "Any real world dataset may come along with several problems. The problem of **imbalanced class** is one of them. The problem of imbalanced classes arises when one set of classes dominate over another set of classes. The former is called majority class while the latter is called minority class. It causes the machine learning model to be more biased towards majority class. It causes poor classification of minority classes. Hence, this problem throw the question of “accuracy” out of question. This is a very common problem in machine learning where we have datasets with a disproportionate ratio of observations in each class.\n",
        "\n",
        "\n",
        "**Imbalanced classes problem** is one of the major problems in the field of data science and machine learning. It is very important that we should properly deal with this problem and develop our machine learning model accordingly.  If this not done, then we may end up with higher accuracy. But this higher accuracy is meaningless because it comes from a meaningless metric which is not suitable for the dataset in question. Hence, this higher accuracy no longer reliably measures model performance.  \n",
        "\n",
        "\n",
        "For more information on imbalanced classes problem, please read the following document - [Data Preprocessing Project - Imbalanced Classes Problem](https://github.com/pb111/Data-Preprocessing-Project-Imbalanced-Classes-Problem)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hOnj96pyhHx"
      },
      "source": [
        "## 2. Problems with imbalanced learning\n",
        "\n",
        "\n",
        "The problem of imbalanced classes is very common and it is bound to happen. For example, in the above example the number of patients who do not have the rare disease is much larger than the number of patients who have the rare disease. So, the model does not correctly classify the patients who have the rare disease. This is where the problem arises.\n",
        "\n",
        "\n",
        "The problem of learning from imbalanced data have new and modern approaches. This learning from imbalanced data is referred to as **imbalanced learning**.  \n",
        "\n",
        "\n",
        "Significant problems may arise with imbalanced learning. These are as follows:-\n",
        "\n",
        "\n",
        "1.\tThe class distribution is skewed when the dataset has underrepresented data.\n",
        "\n",
        "2.\tThe high level of accuracy is simply misleading. In the previous example, it is high because most patients do not \n",
        "    have the disease not because of the good model.    \n",
        "    \n",
        "3.\tThere may be inherent complex characteristics in the dataset. Imbalanced learning from such dataset requires new \n",
        "    approaches, principles, tools and techniques. But, it cannot guarantee an efficient solution to the business problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuUe74hYyhHy"
      },
      "source": [
        "## 3. Example of imbalanced classes\n",
        "\n",
        "\n",
        "The problem of imbalanced classes may appear in many areas including the following:-\n",
        "\n",
        "\n",
        "1.\tDisease detection\n",
        "\n",
        "2.\tFraud detection\n",
        "\n",
        "3.\tSpam filtering\n",
        "\n",
        "4.\tEarthquake prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yCEwJdDyhHz"
      },
      "source": [
        "## 4. Approaches to handle imbalanced classes\n",
        "\n",
        "\n",
        "In this section, I will list various approaches to deal with the imbalanced class problem. These approaches may fall under two categories – dataset level approach and algorithmic ensemble techniques approach. The various methods to deal with imbalanced class problem are listed below. I will describe these techniques in more detail in the following sections.\n",
        "\n",
        "\n",
        "1.\tRandom Undersampling methods\n",
        "\n",
        "2.\tRandom Oversampling methods\n",
        "\n",
        "3.  Tree-based algorithms\n",
        "\n",
        "4. Resampling with imbalanced-learn\n",
        "\n",
        "5. Under-sampling : Tomek links\n",
        "\n",
        "6. Under-sampling : Cluster Centroids\n",
        "\n",
        "7. Over-sampling : SMOTE\n",
        "\n",
        "\n",
        "I have discussed these methods in detail in the readme document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MKnJ-VfyhHz"
      },
      "source": [
        "## 5. Python implementation to illustrate class imbalance problem\n",
        "\n",
        "\n",
        "\n",
        "Now, I will perform Python implementation to illustrate class imbalance problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZOhSqV5yhH0"
      },
      "source": [
        "### Import Python libraries\n",
        "\n",
        "I will start off by importing the required Python libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtbW4zQDyhH0"
      },
      "source": [
        "# import Python libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQEKGECKyhH1"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmSqzRdSyhH2"
      },
      "source": [
        "### Import dataset\n",
        "\n",
        "\n",
        "Now, I will import the dataset with the usual Python `read_csv()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSWuNReWy9tr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddfa7892-2ea6-469f-e139-ce1cdbedefec"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik2wCMX_yhH2"
      },
      "source": [
        "file_path = '/content/drive/MyDrive/datasets/creditcardfrauds/creditcard.csv'\n",
        "\n",
        "df = pd.read_csv(file_path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuEOHn45yhH2"
      },
      "source": [
        "### Dataset description\n",
        "\n",
        "\n",
        "I have used the **Credit Card Fraud Detecttion** dataset for this project. I have downloaded this project from the Kaggle website. This dataset can be found at the following url-\n",
        "\n",
        "\n",
        "https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
        "\n",
        "\n",
        "This dataset contains transactions made by european credit card holders in September 2013. It represents transactions that occurred in two days. We have 492 fraudulent transactions out of total 284,807 transactions. This dataset is highly unbalanced, the positive class (frauds) account for only 0.172% of all transactions.\n",
        "\n",
        "\n",
        "Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise. So, our target variable is `Class` variable.\n",
        "\n",
        "\n",
        "\n",
        "Given the class imbalance ratio, it is recommended to measure the accuracy using the `Area Under the Precision-Recall Curve (AUPRC)`. Confusion matrix accuracy is not meaningful for unbalanced classification.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HObrnQ7MyhH3"
      },
      "source": [
        "### Exploratory data analysis\n",
        "\n",
        "\n",
        "Now, I will conduct exploratory data analysis to gain an insight into the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EmRLmbsyhH4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bff23bb-c02b-4d70-a715-4735a9b5921b"
      },
      "source": [
        "# check shape of dataset\n",
        "\n",
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9gSfZz2yhH6"
      },
      "source": [
        "We can see that there are 284,807 instances and 31 columns in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS-NHkXFyhH6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "e1401d04-8d50-4e0d-d5da-d7532a5b6a75"
      },
      "source": [
        "# preview of the dataset\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRrraPwryhH7"
      },
      "source": [
        "The `df.head()` function gives the preview of the dataset. We can see that there is a `Class` column in the dataset which is our target variable.\n",
        "\n",
        "\n",
        "I will check the distribution of the `Class` column with the `value_counts()` method as follows:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93O8Sn4lyhH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b98304-4075-4306-fdec-be692bead824"
      },
      "source": [
        "# check the distribution of Class column\n",
        "\n",
        "df['Class'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UyvOxPTyhH8"
      },
      "source": [
        "So, we have 492 fraudulent transactions out of total 284,807 transactions in the dataset. The `Class` column takes value `1 for \n",
        "fraudulent transactions` and `0 for non-fraudulent transactions`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsJMR_uAyhH8"
      },
      "source": [
        "Now, I will find the percentage of labels 0 and 1 within the `Class` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC3KCoviyhH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aebec983-740b-459e-b7d5-eb894a8a7974"
      },
      "source": [
        "# percentage of labels within the Class column\n",
        "\n",
        "df['Class'].value_counts()/np.float(len(df))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.998273\n",
              "1    0.001727\n",
              "Name: Class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo7P9mv-yhH9"
      },
      "source": [
        "We can see that the `Class` column is highly imbalanced. It contains 99.82% labels as `0` and 0.17% labels as `1`. \n",
        "\n",
        "Now, I will plot the bar plot to confirm this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIyaj8lZyhH9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "bc564b40-bef1-44f3-f63c-6b713f72fd94"
      },
      "source": [
        "# view the distribution of percentages within the Class column\n",
        "\n",
        "\n",
        "(df['Class'].value_counts()/np.float(len(df))).plot.bar()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f70d0eb1a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "org7VRuwyhH-"
      },
      "source": [
        "The above bar plot confirms our finding that the `Class` variable is highly imbalanced. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdUIIrHryhH-"
      },
      "source": [
        "### Misleading accuracy for imbalanced classes\n",
        "\n",
        "\n",
        "Now, I will demonstrate that accuracy is misleading for imbalanced classes. Most of the machine learning algorithms are designed to maximize the overall accuracy by default. But this maximum accuracy is misleading. We can confirm this with the following analysis.\n",
        "\n",
        "\n",
        "I will fit a very simple Logistic Regression model using the default settings. I will train the classifier on the imbalanced dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9gXEPO-yhH-"
      },
      "source": [
        "# declare feature vector and target variable\n",
        "\n",
        "X = df.drop(['Class'], axis=1)\n",
        "y = df['Class']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-bbaqdnyhH_"
      },
      "source": [
        "# import Logistic Regression classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# instantiate the Logistic Regression classifier\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "\n",
        "# fit the classifier to the imbalanced data\n",
        "clf = logreg.fit(X, y)\n",
        "\n",
        "\n",
        "# predict on the training data\n",
        "y_pred = clf.predict(X)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQrMZzdpyhH_"
      },
      "source": [
        "Now, I have trained the model. I will check its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ha6yrL5yhH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3322a46-9929-4d92-c4b2-fd951f83a617"
      },
      "source": [
        "# import the accuracy metric\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# print the accuracy\n",
        "accuracy = accuracy_score(y_pred, y)\n",
        "\n",
        "print(\"Accuracy : %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 99.89%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crMH7rshyhIA"
      },
      "source": [
        "### Accuracy paradox\n",
        "\n",
        "\n",
        "Thus, our Logistic Regression model for credit card fraud detection has an accuracy of 99.90%. It means that for each 100 transactions it classified, 99.90% were classified as genuine.\n",
        "\n",
        "\n",
        "It does not mean that our model performance is excellent. I have previously shown that our dataset have 99.90% genuine transactions and 0.1% fraudulent transactions. Our Logistic Regression classifier predicted all transactions as genuine. \n",
        "Then we have a accuracy of 99.90% because it correctly classified 99.90% transactions as genuine.\n",
        "\n",
        "\n",
        "Thus, this algorithm is 99.90% accurate. But it was horrible at classifying fraudulent transactions. So, we should have other ways to measure the model performance. One such measure is confusion matrix described below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmEe5p62yhIA"
      },
      "source": [
        "### Confusion matrix\n",
        "\n",
        "\n",
        "A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n",
        "\n",
        "\n",
        "Four types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n",
        "\n",
        "\n",
        "**True Positives (TP)** – True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n",
        "\n",
        "\n",
        "**True Negatives (TN)** – True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n",
        "\n",
        "\n",
        "**False Positives (FP)** – False Positives occur when we predict an observation belongs to a    certain class but the observation actually does not belong to that class. This type of error is called **Type I error.**\n",
        "\n",
        "\n",
        "\n",
        "**False Negatives (FN)** – False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called **Type II error.**\n",
        "\n",
        "\n",
        "\n",
        "These four outcomes are summarized in a confusion matrix given below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfJuUEZgyhIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68ab64e-7a80-415e-c30e-3d712ebde119"
      },
      "source": [
        "# import the metric\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "# print the confusion matrix\n",
        "cnf_matrix = confusion_matrix(y, y_pred)\n",
        "\n",
        "\n",
        "print('Confusion matrix:\\n', cnf_matrix)\n",
        "                             "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            " [[284158    157]\n",
            " [   151    341]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcOOUvrsyhID"
      },
      "source": [
        "### Interpretation of confusion matrix\n",
        "\n",
        "\n",
        "Now, I will interpret the confusion matrix.\n",
        "\n",
        "\n",
        "-  Out of the total 284315 transactions which were predicted genuine, the classifier predicted correctly 284240 of them. It means that the classifer predicted 284240 transactions as genuine and they were actually genuine. Also, it predicted 75 transactions as genuine but it were fraudulent. So, we have `284240 True Positives(TP)` and `75 False Positives(FP)`.\n",
        "\n",
        "\n",
        "-  Out of the total 492 transactions which were not predicted as genuine, the classifier predicted correctly 289 of them. It means that the classifer did not predict 289 transactions as genuine and they were actually not genuine. SO, they were fraudulent. Also, it did not predict 203 transactions as genuine but they were genuine. So, we have `289 True Negatives(TN)` and `203 False Negatives(FN)`.\n",
        "\n",
        "\n",
        "\n",
        "-  So, out of all the 284807 transactions, the classifier correctly predicted 284529 of them. Thus, we will get the accuracy of\n",
        "`(284240+289)/(284240+289+75+203) = 99.90%.`\n",
        "\n",
        "\n",
        "\n",
        "-  But this is not the true picture. The confusion matrix allows us to obtain a true picture of the performance of the algorithm. The algorithm tries to predict the fraudulent transactions out of the total transactions. It correctly predicted 289 transactions as fraudulent out of all the 284807 transactions.  In this case the accuracy becomes `(289/284807)=0.10%.`\n",
        "\n",
        "\n",
        "\n",
        "- Moreover, we have `203+289=492` transactions as fraudulent. The algorithm is correctly classifying 289 of them as fraudulent while it fails to predict 203 transactions which were fraudulent. In this case the accuracy becomes `(289/492)=58.74%.`\n",
        "\n",
        "\n",
        "So, we can conclude that the accuracy of 99.90% is misleading because we have imbalanced classes. We need more subtle way to evaluate the performance of the model.\n",
        "\n",
        "\n",
        "There is another metric called `Classification Report` which helps to evaluate model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mtG61quyhID"
      },
      "source": [
        "###  Classification report\n",
        "\n",
        "\n",
        "\n",
        "**Classification report** is another way to evaluate the classification model performance. It displays the  **precision**, **recall**, **f1** and **support** scores for the model. I have described these terms in later sections.\n",
        "\n",
        "\n",
        "\n",
        "We can plot a classification report as follows:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w40ZMuJyhID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23718347-fa11-4505-c3e2-80e39a9a43c0"
      },
      "source": [
        "# import the metric\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# print classification report\n",
        "print(\"Classification Report:\\n\\n\", classification_report(y, y_pred))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    284315\n",
            "           1       0.68      0.69      0.69       492\n",
            "\n",
            "    accuracy                           1.00    284807\n",
            "   macro avg       0.84      0.85      0.84    284807\n",
            "weighted avg       1.00      1.00      1.00    284807\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcSfF9_kyhIE"
      },
      "source": [
        "### Precision\n",
        "\n",
        "\n",
        "Precision can be defined as the percentage of correctly predicted positive outcomes out of all the predicted positive outcomes.\n",
        "It can be given as the ratio of true positives (TP) to the sum of true and false positives (TP + FP). \n",
        "\n",
        "\n",
        "Mathematically, **precision** can be defined as the ratio of `TP to (TP + FP).`\n",
        "\n",
        "\n",
        "So, precision is more concerned with the positive class than the negative class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m59uJW7yhIE"
      },
      "source": [
        "### Recall\n",
        "\n",
        "\n",
        "Recall can be defined as the percentage of correctly predicted positive outcomes out of all the actual positive outcomes.\n",
        "It can be given as the ratio of true positives (TP) to the sum of true positives and false negatives (TP + FN). **Recall** is also called **Sensitivity**.\n",
        "\n",
        "\n",
        "Mathematically, **recall** can be given as the ratio of `TP to (TP + FN).`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpvrE2OtyhIF"
      },
      "source": [
        "### f1-score\n",
        "\n",
        "\n",
        "**f1-score** is the weighted harmonic mean of precision and recall. The best possible **f1-score** would be 1.0 and the worst \n",
        "would be 0.0.  **f1-score** is the harmonic mean of precision and recall. So, **f1-score** is always lower than accuracy measures as they embed precision and recall into their computation. The weighted average of `f1-score` should be used to \n",
        "compare classifier models, not global accuracy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKv7a1CeyhIF"
      },
      "source": [
        "### Support\n",
        "\n",
        "\n",
        "**Support** is the actual number of occurrences of the class in our dataset. It classifies `284315 transactions as genuine` and `492 transactions as fraudulent`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drOHe1Z0yhIF"
      },
      "source": [
        "### ROC Curve\n",
        "\n",
        "\n",
        "Another tool to measure the classification model performance visually is **ROC Curve**. ROC Curve stands for **Receiver Operating Characteristic Curve**. \n",
        "\n",
        "\n",
        "The **ROC Curve** plots the **True Positive Rate (TPR)** against the **False Positive Rate (FPR)** at various threshold levels.\n",
        "\n",
        "\n",
        "**True Positive Rate (TPR)** is also called **Recall**. It is defined as the ratio of `TP to (TP + FN).`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**False Positive Rate (FPR)** is defined as the ratio of `FP to (FP + TN).`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The **Receiver Operating Characteristic Area Under Curve (ROC AUC)** is the area under the ROC curve. The higher it is, the better the model is. \n",
        "\n",
        "\n",
        "In the ROC Curve, we will focus on the TPR (True Positive Rate) and FPR (False Positive Rate) of a single point. This will give us the general performance of the ROC curve which consists of the TPR and FPR at various probability thresholds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL7owuu2yhIF"
      },
      "source": [
        "### Precision - Recall Curve\n",
        "\n",
        "\n",
        "\n",
        "Another tool to measure the classification model performance is **Precision-Recall Curve**. It is a useful metric which is used to evaluate a classifier model performance when classes are very imbalanced such as in this case. This **Precision-Recall Curve** shows the trade off between precision and recall.\n",
        "\n",
        "\n",
        "\n",
        "In a **Precision-Recall Curve**, we plot **Precision** against **Recall**.\n",
        "\n",
        "\n",
        "**Precision** is defined as the ratio of `TP to (TP + FP).`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Recall** is defined as the ratio of `TP to (TP + FN).`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The **Precision Recall Area Under Curve (PR AUC)** is the area under the PR curve. The higher it is, the better the model is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QzkkVIcyhIG"
      },
      "source": [
        "### Difference between ROC AUC and PR AUC\n",
        "\n",
        "\n",
        "- Precision-Recall does not account for True Negatives (TN) unlike ROC AUC (TN is not a component of either Precision or Recall). \n",
        "\n",
        "\n",
        "- In the cases of class imbalance problem, we have many more negatives than positives. The Precision-Recall curve much better illustrates the difference between algorithms in the class imbalance problem cases where there are lot more negative examples than the positive examples. In these cases of class imbalances, we should use Precision-Recall Curve (PR AUC), otherwise we should use ROC AUC.\n",
        "\n",
        "\n",
        "So, we can conclude that we should use PR AUC for cases where the class imbalance problem occurs. Otherwise, we should use ROC AUC.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s73gKLLyhIG"
      },
      "source": [
        "## 6. Precision - Recall Curve \n",
        "\n",
        "\n",
        "In the previous section, we conclude that we should use `Precision-Recall Area Under Curve` for cases where the class imbalance problem exists. Otherwise, we should use `ROC-AUC (Receiver Operating Characteristic Area Under Curve)`.\n",
        "\n",
        "\n",
        "Now, I will compute the `average precision score`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBvMqbWOyhIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3606fb6-1e81-4588-b83b-1de17adf7d2e"
      },
      "source": [
        "# compute and print average precision score\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "average_precision = average_precision_score(y_pred, y)\n",
        "\n",
        "print('Average precision-recall score : {0:0.2f}'.format(average_precision))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average precision-recall score : 0.48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX9U3zZwyhIG"
      },
      "source": [
        "`Precision-Recall Curve` gives us the correct accuracy in this imbalanced dataset case. We can see that we have a very poor accuracy for the model.\n",
        "\n",
        "\n",
        "Now, I will plot the `precision-recall curve`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TNcnUO1yhIH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "0c883b74-a5f3-40cd-df62-457dcd1a5e00"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve \n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_pred, y)\n",
        "\n",
        "# create plot\n",
        "plt.plot(precision, recall, label='Precision-recall curve')\n",
        "plt.xlabel('Precision')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Precision-recall curve')\n",
        "plt.legend(loc=\"lower left\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f70bf63ca10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO2bz2_5yhIH"
      },
      "source": [
        "## 7. Random over-sampling the minority class\n",
        "\n",
        "\n",
        "\n",
        "**Over-sampling** is the process of randomly duplicating observations from the minority class in order to achieve a balanced dataset. So, it replicates the observations from minority class to balance the data. It is also known as **upsampling**. It may result in overfitting due to duplication of data points.  \n",
        "\n",
        "\n",
        "The most common way of over-sampling is to resample with replacement. I will proceed as follows:-\n",
        "\n",
        "\n",
        "First, I will import the resampling module from Scikit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNPPfuNIyhIH"
      },
      "source": [
        "# import resample module \n",
        "\n",
        "from sklearn.utils import resample"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3y3DAd-yhII"
      },
      "source": [
        "Now, I will create a new dataframe with an oversampled minority class as follows:-\n",
        "\n",
        "\n",
        "1. At first, I will separate observations from Class variable into different DataFrames.\n",
        "\n",
        "\n",
        "2. Now, I will resample the minority class with replacement. I will set the number of samples of minority class to match \n",
        "   that of the majority class.\n",
        "\n",
        "\n",
        "3. Finally, I will combine the oversampled minority class DataFrame with the original majority class DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJUJtKbgyhII"
      },
      "source": [
        "# separate the minority and majority classes\n",
        "df_majority = df[df['Class']==0]\n",
        "df_minority = df[df['Class']==1]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfV1gjlnyhII"
      },
      "source": [
        "# oversample minority class\n",
        "\n",
        "df_minority_oversampled = resample(df_minority, replace=True, n_samples=284315, random_state=0)      "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFihJ1LMyhII"
      },
      "source": [
        "# combine majority class with oversampled minority class\n",
        "\n",
        "df_oversampled = pd.concat([df_majority, df_minority_oversampled])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji-XiX4VyhIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ee5179-70eb-4bfe-d721-86d14a2d7b53"
      },
      "source": [
        "# display new class value counts\n",
        "\n",
        "df_oversampled['Class'].value_counts()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    284315\n",
              "0    284315\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JU5iJt5yhIJ"
      },
      "source": [
        "Now, we can see that we have a balanced dataset. The ratio of the two class labels is now 1:1.\n",
        "\n",
        "Now, I will plot the bar plot of the above two classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdCcY96YyhIK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "3ddec586-0fc9-45ee-cd5b-b480b73596b9"
      },
      "source": [
        "# view the distribution of percentages within the Class column\n",
        "\n",
        "\n",
        "(df_oversampled['Class'].value_counts()/np.float(len(df_oversampled))).plot.bar()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f70bff7bbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIDXS2wPyhIK"
      },
      "source": [
        "The above bar plot shows that we have a balanced dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blzw2E-UyhIK"
      },
      "source": [
        "Now, I will train another model using Logistic Regression and check its accuracy, but this time on the balanced dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRvuIRIcyhIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ce70d4-3a0c-480a-e382-450a9065ebf3"
      },
      "source": [
        "# declare feature vector and target variable\n",
        "X1 = df_oversampled.drop(['Class'], axis=1)\n",
        "y1 = df_oversampled['Class']\n",
        "\n",
        "\n",
        "# instantiate the Logistic Regression classifier\n",
        "logreg1 = LogisticRegression()\n",
        "\n",
        "\n",
        "# fit the classifier to the imbalanced data\n",
        "clf1 = logreg1.fit(X1, y1)\n",
        "\n",
        "\n",
        "# predict on the training data\n",
        "y1_pred = clf1.predict(X1)\n",
        "\n",
        "\n",
        "# print the accuracy\n",
        "accuracy1 = accuracy_score(y1_pred, y1)\n",
        "\n",
        "print(\"Accuracy : %.2f%%\" % (accuracy1 * 100.0))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 94.51%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPCHjaS7yhIL"
      },
      "source": [
        "We now have a balanced dataset. Although the accuracy is slightly decreased, but it is still quite high and acceptable. \n",
        "This accuracy is more meaningful as a performance metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPkkLfouyhIL"
      },
      "source": [
        "## 8. Random under-sampling the majority class\n",
        "\n",
        "\n",
        "The **under-sampling** methods work with the majority class. In these methods, we randomly eliminate instances of the majority class. It reduces the number of observations from majority class to make the dataset balanced. This method is applicable when the dataset is huge and reducing the number of training samples make the dataset balanced.\n",
        "\n",
        "\n",
        "The most common technique for under-sampling is resampling without replacement.\n",
        "\n",
        "\n",
        "I will proceed exactly as in the case of random over-sampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1M7AJi-yhIL"
      },
      "source": [
        "# separate the minority and majority classes\n",
        "df_majority = df[df['Class']==0]\n",
        "df_minority = df[df['Class']==1]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpXwEGZOyhIM"
      },
      "source": [
        "# undersample majority class\n",
        "\n",
        "df_majority_undersampled = resample(df_majority, replace=True, n_samples=492, random_state=0) "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R6WGExDyhIM"
      },
      "source": [
        "# combine majority class with oversampled minority class\n",
        "\n",
        "df_undersampled = pd.concat([df_minority, df_majority_undersampled])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjM7RpruyhIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe67374-8d07-4563-9f85-a029ea47dfd9"
      },
      "source": [
        "# display new class value counts\n",
        "\n",
        "df_undersampled['Class'].value_counts()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    492\n",
              "0    492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a92bp1TtyhIM"
      },
      "source": [
        "Now, we can see that the new dataframe `df_undersampled` has fewer observations than the original one `df` and the ratio of the two classes is now 1:1.\n",
        "\n",
        "Again, I will train a model using Logistic Regression classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq7mwLa2yhIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be72eedb-8aaa-4b14-a25c-4e27ffa34cf3"
      },
      "source": [
        "# declare feature vector and target variable\n",
        "X2 = df_undersampled.drop(['Class'], axis=1)\n",
        "y2 = df_undersampled['Class']\n",
        "\n",
        "\n",
        "# instantiate the Logistic Regression classifier\n",
        "logreg2 = LogisticRegression()\n",
        "\n",
        "\n",
        "# fit the classifier to the imbalanced data\n",
        "clf2 = logreg2.fit(X2, y2)\n",
        "\n",
        "\n",
        "# predict on the training data\n",
        "y2_pred = clf2.predict(X2)\n",
        "\n",
        "\n",
        "# print the accuracy\n",
        "accuracy2 = accuracy_score(y2_pred, y2)\n",
        "\n",
        "print(\"Accuracy : %.2f%%\" % (accuracy2 * 100.0))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 93.19%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nw5ZC5MyhIN"
      },
      "source": [
        "Again, we can see that we have a slightly decreased accuracy but it is more meaningful now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEjLIUISyhIN"
      },
      "source": [
        "## 9. Apply Tree-Based Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1CmRAIvyhIO"
      },
      "source": [
        "# declare input features (X) and target variable (y)\n",
        "X4 = df.drop('Class', axis=1)\n",
        "y4 = df['Class']\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fY4MmIgyhIO"
      },
      "source": [
        "# import Random Forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UES3B9jjyhIO"
      },
      "source": [
        "# instantiate the classifier \n",
        "clf4 = RandomForestClassifier()\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPPEJSAbyhIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed7064e-7a07-4fc8-f3b5-ef85bab761ef"
      },
      "source": [
        "# fit the classifier to the training data\n",
        "clf4.fit(X4, y4)\n",
        " "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29M0iKKNyhIP"
      },
      "source": [
        "# predict on training set\n",
        "y4_pred = clf4.predict(X4)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU2HdhO0yhIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80e4342-068f-45b7-e17b-0c9b50aaae45"
      },
      "source": [
        "# compute and print accuracy\n",
        "accuracy4 = accuracy_score(y4_pred, y4)\n",
        "print(\"Accuracy : %.2f%%\" % (accuracy4 * 100.0))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBH0goedyhIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168011f5-db53-432a-eece-8e88f3a03e8d"
      },
      "source": [
        "# compute and print ROC-AUC\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y4_prob = clf4.predict_proba(X4)\n",
        "y4_prob = [p[1] for p in y4_prob]\n",
        "print(\"ROC-AUC : \" , roc_auc_score(y4, y4_prob))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC-AUC :  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLO4bmN0yhIQ"
      },
      "source": [
        "## 10.\tRandom under-sampling and over-sampling with imbalanced-learn\n",
        "\n",
        "\n",
        "\n",
        "There is a Python library which enable us to handle the imbalanced datasets. It is called **Imbalanced-Learn**. It is a Python library which contains various algorithms to handle the imbalanced datasets. It can be easily installed with the `pip` command. This library contains a `make_imbalance` method to exasperate the level of class imbalance within a given dataset.\n",
        "\n",
        "\n",
        "Now, I will demonstrate the technique of random undersampling and oversampling with imbalanced learn. \n",
        "\n",
        "\n",
        "First of all, I will import the `imbalanced learn` library.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgaKUK7eyhIQ"
      },
      "source": [
        "# import imbalanced learn library\n",
        "\n",
        "import imblearn"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yehrn8NyhIQ"
      },
      "source": [
        "Then, I will import the `RandomUnderSampler` class. It is a quick and easy way to balance the data by randomly selecting a subset of data for the targeted classes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuVHaGiQyhIR"
      },
      "source": [
        "# import RandomUnderSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# instantiate the RandomUnderSampler\n",
        "rus = RandomUnderSampler(return_indices=True)\n",
        "\n",
        "\n",
        "# fit the RandomUnderSampler to the dataset\n",
        "X_rus, y_rus, id_rus = rus.fit_sample(X, y)\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVOjlBjqyhIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067e65ab-330c-499f-d395-5bc00a1d7b4c"
      },
      "source": [
        "# print the removed indices\n",
        "print(\"Removed indices: \", id_rus)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removed indices:  [ 43375  77216  24218 221550 199686 168747  58369 161284  21482 175282\n",
            " 194218 101218  11310  89819  42129 140905  65984 171325  79529  85253\n",
            "  86331 197672 276142 138799 126433 109566   5833 244787 202535  51177\n",
            "  65294  24415 124807 163025 149973   2853 147199 141570  82064  41540\n",
            "  24815 194859  70629  71465  99084 122207 159629 246896 223551  90369\n",
            " 170877 198884 200469 115431  41465   2017  18876 108042 123567 102247\n",
            " 256837  46271  68996 143716 272514   8050  64697 221890 118637 265386\n",
            "  34562 153594  50539 104538 258198   1031 118260 128876 100305  78418\n",
            "  30684 103286 118593 188465 165347 233480  36510 166243 212201  11272\n",
            " 128882 182890 122991 181496 100226 235163  32369 156098 178279  31151\n",
            " 199170 147821 188934 157418  31705  43910  36795 156250  13998  83674\n",
            " 112580 101880  85169  93041 225671 243391 211849  98462   6441 180833\n",
            " 121477 268356 107317 191494 101541  75530  87325  45593 162544 173724\n",
            "  95469 277884  80837 225842  79060 183956   9282 207056 206479  90866\n",
            "   3986 250027 160315 280798 201838  41164  48540  98788 240766 199081\n",
            "  90466 185322 199401 276838  43310  39319  57783 150996 251496 147174\n",
            " 233745  92182 228198 282283  80350  33035 246237 158674 207930  75154\n",
            "  80340  24674 191120  67740 175095  81848 126322  70599 225694  85602\n",
            " 265505 207537 190640 255508 236578  40961 279814 149450 205350 112457\n",
            " 238065 229451 246368 279809 173853 213839  62124 107771  34701  72688\n",
            " 268742  17757 181734 210214 277749 215856  54209 210995 103034 150471\n",
            "  26767 184998  75973 226210 139367  92010  77275 122395  59176 215795\n",
            " 175306 180808  12356 137891 168206  30068  80618 258308  59702 142106\n",
            " 143309  36717 195346 154436 265259 264496  47963 210189 137229 111281\n",
            " 178428  39922 265343  39535 110970  59017  44299 236312 236399 206347\n",
            "  31967  17110 100362 207764 271343   8163 193749  37532 208550 127011\n",
            " 284142  20819 201328  50515 199596 128085 267995  50947 136789  44770\n",
            " 243286 207216 212580 235608  12888 254283  54270  29057 129561  48942\n",
            " 118769  37073  72011 171844 236960  10573 184065 199046 238533  26058\n",
            " 190351  52362 120200 110578   8930 233324 265267  85041   7455  70256\n",
            "   9582  55959  45652 245194  31938 273213  77688 105045 233846 273680\n",
            " 267675 277289 159986 115323  11353  49766 137794 213703  82595  45171\n",
            "  76486 134455  60009 207237  52873   2842 231162  38138   6398  43927\n",
            " 171471 103037 208824 230084  59880 256491 229129 130034 173619 162420\n",
            " 251720 251347   7578 165162 154557 232559  71098 251816 198519  74577\n",
            "  79681 276557 212153 196668 266645    105 220666  77495  44321 196158\n",
            "  48768 123761 253040 155424  67742  68939  10159 247144 178385  15549\n",
            " 249788 155152  51795  82164  95818  79749 241747  46033  43769 177978\n",
            "   4261 102095 101557 249737 229105  63387 130227 227080 278317  61903\n",
            " 251923 196320 108224  41740  59760 144523 101861 101071 172889  18549\n",
            "   7760 192931  25836  43523 133918  91150 218891 131005  19937 240902\n",
            "  26833 238563  88154 214112 163997 195562  16339  60697  82580 160946\n",
            " 280747 150123  53851 221804 185244 242791 221683  99476 145713 160266\n",
            "  24771 201431  95545 127522   2238 188361 270860 248344   8880 189082\n",
            " 223868  11925  18416   8314 155794 112356 240294 173291 142768  37290\n",
            " 211713 212681 107593 208603 139144 170024  98894  64364  45907 117723\n",
            " 111463 220592 261526 110761 264113 191423  38246 249741 145508 171712\n",
            " 203168  22514 280502 247684 228775 273982 191223 190534 229052 174743\n",
            "  37722 123277  34698 155158 204006 185183  93199 137012  16466 198814\n",
            " 272687  26234    541    623   4920   6108   6329   6331   6334   6336\n",
            "   6338   6427   6446   6472   6529   6609   6641   6717   6719   6734\n",
            "   6774   6820   6870   6882   6899   6903   6971   8296   8312   8335\n",
            "   8615   8617   8842   8845   8972   9035   9179   9252   9487   9509\n",
            "  10204  10484  10497  10498  10568  10630  10690  10801  10891  10897\n",
            "  11343  11710  11841  11880  12070  12108  12261  12369  14104  14170\n",
            "  14197  14211  14338  15166  15204  15225  15451  15476  15506  15539\n",
            "  15566  15736  15751  15781  15810  16415  16780  16863  17317  17366\n",
            "  17407  17453  17480  18466  18472  18773  18809  20198  23308  23422\n",
            "  26802  27362  27627  27738  27749  29687  30100  30314  30384  30398\n",
            "  30442  30473  30496  31002  33276  39183  40085  40525  41395  41569\n",
            "  41943  42007  42009  42473  42528  42549  42590  42609  42635  42674\n",
            "  42696  42700  42741  42756  42769  42784  42856  42887  42936  42945\n",
            "  42958  43061  43160  43204  43428  43624  43681  43773  44001  44091\n",
            "  44223  44270  44556  45203  45732  46909  46918  46998  47802  48094\n",
            "  50211  50537  52466  52521  52584  53591  53794  55401  56703  57248\n",
            "  57470  57615  58422  58761  59539  61787  63421  63634  64329  64411\n",
            "  64460  68067  68320  68522  68633  69498  69980  70141  70589  72757\n",
            "  73784  73857  74496  74507  74794  75511  76555  76609  76929  77099\n",
            "  77348  77387  77682  79525  79536  79835  79874  79883  80760  81186\n",
            "  81609  82400  83053  83297  83417  84543  86155  87354  88258  88307\n",
            "  88876  88897  89190  91671  92777  93424  93486  93788  94218  95534\n",
            "  95597  96341  96789  96994  99506 100623 101509 102441 102442 102443\n",
            " 102444 102445 102446 102782 105178 106679 106998 107067 107637 108258\n",
            " 108708 111690 112840 114271 116139 116404 118308 119714 119781 120505\n",
            " 120837 122479 123141 123201 123238 123270 123301 124036 124087 124115\n",
            " 124176 125342 128479 131272 135718 137705 140786 141257 141258 141259\n",
            " 141260 142405 142557 143188 143333 143334 143335 143336 143728 143731\n",
            " 144104 144108 144754 145800 146790 147548 147605 149145 149357 149522\n",
            " 149577 149587 149600 149869 149874 150601 150644 150647 150654 150660\n",
            " 150661 150662 150663 150665 150666 150667 150668 150669 150677 150678\n",
            " 150679 150680 150684 150687 150692 150697 150715 150925 151006 151007\n",
            " 151008 151009 151011 151103 151196 151462 151519 151730 151807 152019\n",
            " 152223 152295 153823 153835 153885 154234 154286 154371 154454 154587\n",
            " 154633 154668 154670 154676 154684 154693 154694 154697 154718 154719\n",
            " 154720 154960 156988 156990 157585 157868 157871 157918 163149 163586\n",
            " 167184 167305 172787 176049 177195 178208 181966 182992 183106 184379\n",
            " 189587 189701 189878 190368 191074 191267 191359 191544 191690 192382\n",
            " 192529 192584 192687 195383 197586 198868 199896 201098 201601 203324\n",
            " 203328 203700 204064 204079 204503 208651 212516 212644 213092 213116\n",
            " 214662 214775 215132 215953 215984 218442 219025 219892 220725 221018\n",
            " 221041 222133 222419 223366 223572 223578 223618 226814 226877 229712\n",
            " 229730 230076 230476 231978 233258 234574 234632 234633 234705 235616\n",
            " 235634 235644 237107 237426 238222 238366 238466 239499 239501 240222\n",
            " 241254 241445 243393 243547 243699 243749 243848 244004 244333 245347\n",
            " 245556 247673 247995 248296 248971 249167 249239 249607 249828 249963\n",
            " 250761 251477 251866 251881 251891 251904 252124 252774 254344 254395\n",
            " 255403 255556 258403 261056 261473 261925 262560 262826 263080 263274\n",
            " 263324 263877 268375 272521 274382 274475 275992 276071 276864 279863\n",
            " 280143 280149 281144 281674]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4hu6IITyhIS"
      },
      "source": [
        "The above indices are removed from the original dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRQGejVzyhIT"
      },
      "source": [
        "Now, I will demonstrate random oversampling. The process will be the same as random undersampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXs9vqMKyhIT"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler()\n",
        "\n",
        "X_ros, y_ros = ros.fit_sample(X, y)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2xXznnCyhIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23bd2bad-c130-404c-9322-4b87ab8e2589"
      },
      "source": [
        "print(X_ros.shape[0] - X.shape[0], 'new random points generated')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "283823 new random points generated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-oWM_dYyhIU"
      },
      "source": [
        "## 11.\tUnder-sampling : Tomek links\n",
        "\n",
        "\n",
        "Tomek links are defined as the two observations of different classes which are nearest neighbours of each other.\n",
        "\n",
        "\n",
        "The figure below illustrate the concept of Tomek links-\n",
        "\n",
        "\n",
        "\n",
        "![Tomek%20links.jpg](attachment:Tomek%20links.jpg)\n",
        "\n",
        "\n",
        "\n",
        "We can see in the above image that the Tomek links (circled in green) are given by the pairs of red and blue data points that are nearest neighbors. Most of the classification algorithms face difficulty due to these points. So, I will remove these \n",
        "points and increase the separation gap between two classes.  Now, the algorithms produce more reliable output.\n",
        "\n",
        "This technique will not produce a balanced dataset. It will simply clean the dataset by removing the Tomek links. It may result in an easier classification problem. Thus, by removing the Tomek links, we can improve the performance of the classifier even if we don’t have a balanced dataset.\n",
        "\n",
        "\n",
        "So, removing the Tomek links increases the gap between the two classes and thus facilitate the classification process.\n",
        "\n",
        "\n",
        "In the following code, I will use `ratio=majority` to resample the majority class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3OLw0gJyhIU"
      },
      "source": [
        "from imblearn.under_sampling import TomekLinks\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2MbBx50yhIU"
      },
      "source": [
        "tl = TomekLinks(return_indices=True, ratio='majority')\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVwWIISvyhIU"
      },
      "source": [
        "X_tl, y_tl, id_tl = tl.fit_sample(X, y)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfIs2qKVyhIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0f08bd-c983-4be2-c9f6-36e4f356462b"
      },
      "source": [
        "print('Removed indexes:', id_tl)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removed indexes: [     0      1      2 ... 284804 284805 284806]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AaNGEWbyhIV"
      },
      "source": [
        "## 12. Under-sampling : Cluster Centroids\n",
        "\n",
        "\n",
        "In this technique, we perform under-sampling by generating centroids based on clustering methods. The dataset will be grouped\n",
        "by similarity, in order to preserve information.\n",
        "\n",
        "In this example, I have passed the {0: 10} dict for the parameter ratio. It preserves 10 elements from the majority class (0), and all minority class (1) ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWs71xtXyhIV"
      },
      "source": [
        "from imblearn.under_sampling import ClusterCentroids"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCFgM2qwyhIW"
      },
      "source": [
        "cc = ClusterCentroids(ratio={0: 10})"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4WW33K1yhIW"
      },
      "source": [
        "X_cc, y_cc = cc.fit_sample(X, y)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePKECvtdyhIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e6fff77-7c84-42e1-e7ca-4110f83e66b0"
      },
      "source": [
        "print(X.shape[0] - X_cc.shape[0], 'New points undersampled under Cluster Centroids')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "284305 New points undersampled under Cluster Centroids\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQp-QaFZyhIW"
      },
      "source": [
        "## 13.\tOver-sampling : SMOTE\n",
        "\n",
        "\n",
        "\n",
        "In the context of synthetic data generation, there is a powerful and widely used method known as **synthetic minority oversampling technique** or **SMOTE**. Under this technique, artificial data is created based on feature space. \n",
        "Artificial data is generated with bootstrapping and k-nearest neighbours algorithm.  It works as follows:-\n",
        "\n",
        "\n",
        "1.\tFirst of all, we take the difference between the feature vector (sample) under consideration and its nearest neighbour.\n",
        "\n",
        "\n",
        "2.\tThen we multiply this difference by a random number between 0 and 1.\n",
        "\n",
        "\n",
        "3.\tThen we add this number to the feature vector under consideration.\n",
        "\n",
        "\n",
        "4.\tThus we select a random point along the line segment between two specific features.\n",
        "\n",
        "\n",
        "The concept of **SMOTE** can best be illustrated with the following figure:-\n",
        "\n",
        "\n",
        "![smote.png](attachment:smote.png)\n",
        "\n",
        "\n",
        "So, **SMOTE** generates new observations by interpolation between existing observations in the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfpiJhQ6yhIX"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "141z9wNZyhIX"
      },
      "source": [
        "smote = SMOTE(ratio='minority')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjXPZKuDyhIX"
      },
      "source": [
        "X_sm, y_sm = smote.fit_sample(X, y)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr8fkQYEyhIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa20b9e9-a13d-4683-d9cf-37780485e14b"
      },
      "source": [
        "print(X_sm.shape[0] - X.shape[0], 'New points created under SMOTE')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "283823 New points created under SMOTE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64tD2O7TyhIY"
      },
      "source": [
        "## 14. Conclusion\n",
        "\n",
        "\n",
        "In this jupyter notebook, I have discussed various approaches to deal with the problem of imbalanced classes. These are `random oversampling`, `random undersampling`, `tree-based algorithms`, `resampling with imbalanced learn library`, `under-sampling : Tomek links`,  `under-sampling : Cluster Centroids` and `over-sampling : SMOTE`.\n",
        "\n",
        "\n",
        "Some combination of these approaches will help us to create a better classifier.  Simple sampling techniques may handle slight imbalance whereas more advanced methods like ensemble methods are required for extreme imbalances.  The most effective technique will vary according to the dataset.\n",
        "\n",
        "\n",
        "So, based on the above discussion, we can conclude that there is no one solution to deal with the imbalanced classes problem. \n",
        "We should try out multiple methods to select the best-suited sampling techniques for the dataset in hand. The most effective technique will vary according to the characteristics of the dataset.\n"
      ]
    }
  ]
}